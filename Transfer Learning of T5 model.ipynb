{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task training of a T5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to leverage other subreddits data to help the model to learn the domain of `Reddit`. The other additional data will be used for the task of \"Title generation\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate title generation train/val set with 'prefix','input_text' and 'target_text' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_link_flair_text</th>\n",
       "      <th>submission_selftext</th>\n",
       "      <th>reply_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f96vya</td>\n",
       "      <td>New versions of A5 and A6 Agile firmwares are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "      <td>[\"There was video of a multifunction button to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>f9dsst</td>\n",
       "      <td>Feature request. Pressure sensitivity.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "      <td>['We are happy that you can enjoy this firmwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fp66n4</td>\n",
       "      <td>Quick Guide â€” Set Up and Connect to the Supern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "      <td>[\"What I would like to know is where can one b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fs454n</td>\n",
       "      <td>How to use handwriting to text function?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "      <td>['Currently you can try the \"Smart Writing\" fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fs46fj</td>\n",
       "      <td>Email inbox issues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "      <td>[\"Hi aubrit512,\\n\\nPlease try to update the sy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index submission_id                                   submission_title  \\\n",
       "0      0        f96vya  New versions of A5 and A6 Agile firmwares are ...   \n",
       "1      1        f9dsst             Feature request. Pressure sensitivity.   \n",
       "2      2        fp66n4  Quick Guide â€” Set Up and Connect to the Supern...   \n",
       "3      3        fs454n           How to use handwriting to text function?   \n",
       "4      4        fs46fj                                 Email inbox issues   \n",
       "\n",
       "  submission_link_flair_text  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "\n",
       "                                 submission_selftext  \\\n",
       "0  Dear Supernote users, new versions of A5 and A...   \n",
       "1  Thank you for the new firmware update. It adds...   \n",
       "2  Set up and connect to the Supernote Cloud acco...   \n",
       "3  How do you achieve this? I've not been able to...   \n",
       "4  I have set up my email, and can send emails. M...   \n",
       "\n",
       "                                          reply_body  \n",
       "0  [\"There was video of a multifunction button to...  \n",
       "1  ['We are happy that you can enjoy this firmwar...  \n",
       "2  [\"What I would like to know is where can one b...  \n",
       "3  ['Currently you can try the \"Smart Writing\" fu...  \n",
       "4  [\"Hi aubrit512,\\n\\nPlease try to update the sy...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Summarize Title\n",
    "title_df = pd.read_csv('competitors_reddit.csv')\n",
    "title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, row in title_df.iterrows():\n",
    "    all_text = ''\n",
    "    if type(row.submission_selftext)==str:\n",
    "        all_text += row.submission_selftext\n",
    "    if type(row.reply_body) ==list:\n",
    "        all_text += ' '.join(row.reply_body[:3]) # Include first 5 replies\n",
    "    \n",
    "    title_df.loc[idx,'all_text'] = all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with no title\n",
    "title_df = title_df[title_df.all_text.str.len()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df[\"prefix\"] = \"title prediction\"\n",
    "title_df = title_df.rename({'all_text':'input_text',\n",
    "                 'submission_title':'target_text'},\n",
    "               axis=1)\n",
    "title_df = title_df[['prefix','input_text', 'target_text']]                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "      <td>New versions of A5 and A6 Agile firmwares are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "      <td>Feature request. Pressure sensitivity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "      <td>Quick Guide â€” Set Up and Connect to the Supern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "      <td>How to use handwriting to text function?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "      <td>Email inbox issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prefix                                         input_text  \\\n",
       "0  title prediction  Dear Supernote users, new versions of A5 and A...   \n",
       "1  title prediction  Thank you for the new firmware update. It adds...   \n",
       "2  title prediction  Set up and connect to the Supernote Cloud acco...   \n",
       "3  title prediction  How do you achieve this? I've not been able to...   \n",
       "4  title prediction  I have set up my email, and can send emails. M...   \n",
       "\n",
       "                                         target_text  \n",
       "0  New versions of A5 and A6 Agile firmwares are ...  \n",
       "1             Feature request. Pressure sensitivity.  \n",
       "2  Quick Guide â€” Set Up and Connect to the Supern...  \n",
       "3           How to use handwriting to text function?  \n",
       "4                                 Email inbox issues  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split into val_title_df and train_title_df with 10% for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_title_df = title_df.sample(frac=0.1,random_state=42)\n",
    "train_title_df = title_df[~title_df.index.isin(val_title_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df = pd.read_csv(\"singletask_train.csv\").astype(str)\n",
    "val_tag_df = pd.read_csv(\"singletask_noupsampling_val.csv\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>Dear Supernote users, new versions of A5 and A...</td>\n",
       "      <td>New versions of A5 and A6 Agile firmwares are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>Thank you for the new firmware update. It adds...</td>\n",
       "      <td>Feature request. Pressure sensitivity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>Set up and connect to the Supernote Cloud acco...</td>\n",
       "      <td>Quick Guide â€” Set Up and Connect to the Supern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>How do you achieve this? I've not been able to...</td>\n",
       "      <td>How to use handwriting to text function?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title prediction</td>\n",
       "      <td>I have set up my email, and can send emails. M...</td>\n",
       "      <td>Email inbox issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prefix                                         input_text  \\\n",
       "0  title prediction  Dear Supernote users, new versions of A5 and A...   \n",
       "1  title prediction  Thank you for the new firmware update. It adds...   \n",
       "2  title prediction  Set up and connect to the Supernote Cloud acco...   \n",
       "3  title prediction  How do you achieve this? I've not been able to...   \n",
       "4  title prediction  I have set up my email, and can send emails. M...   \n",
       "\n",
       "                                         target_text  \n",
       "0  New versions of A5 and A6 Agile firmwares are ...  \n",
       "1             Feature request. Pressure sensitivity.  \n",
       "2  Quick Guide â€” Set Up and Connect to the Supern...  \n",
       "3           How to use handwriting to text function?  \n",
       "4                                 Email inbox issues  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_df = pd.concat([train_title_df,train_tag_df],axis=0)\n",
    "combined_val_df = pd.concat([val_title_df,val_tag_df],axis=0)\n",
    "combined_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from simpletransformers.t5 import T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"output_dir\": './multitask', #specify output directory\n",
    "    \"max_seq_length\": 400,\n",
    "    \"train_batch_size\": 2,\n",
    "    \"eval_batch_size\": 2,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"evaluate_during_training\": True,\n",
    "    #\"evaluate_during_training_steps\": 15000,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    \"evaluate_each_epoch\": True,\n",
    "    \"use_multiprocessing\": False,\n",
    "    \"fp16\": False,\n",
    "    \"save_steps\": -1,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"wandb_project\": \"T5 - single task\",\n",
    "    \"scheduler\": \"polynomial_decay_schedule_with_warmup\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adbf4ae25864a2881a8526b75c22528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1773 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/winnie/miniconda3/envs/project3_env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3282: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adafactor for T5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f5211bc73a4107afd86a807ebe9753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvionwinnie\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">efficient-sunset-36</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/vionwinnie/T5%20-%20single%20task\" target=\"_blank\">https://wandb.ai/vionwinnie/T5%20-%20single%20task</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/vionwinnie/T5%20-%20single%20task/runs/3he1mes5\" target=\"_blank\">https://wandb.ai/vionwinnie/T5%20-%20single%20task/runs/3he1mes5</a><br/>\n",
       "                Run data is saved locally in <code>/home/winnie/Documents/Project 3 (copy)/Milestones/Data/wandb/run-20211008_160507-3he1mes5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708530f285224e47b65e15155fff4cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7e6ff670d24daaa2d04b12296dc794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/winnie/miniconda3/envs/project3_env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3282: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3729e837b7ec42eab3d88d972bddfb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1484c270f745129776ead04299e958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/winnie/miniconda3/envs/project3_env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3282: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad52479f1c2749b197f636d4782afbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39813dcff8c1467dae192763e7f90d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/winnie/miniconda3/envs/project3_env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3282: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72740f23bf64d7d9650ea304773f542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/winnie/miniconda3/envs/project3_env/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3282: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ğŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1292885<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/winnie/Documents/Project 3 (copy)/Milestones/Data/wandb/run-20211008_160507-3he1mes5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/winnie/Documents/Project 3 (copy)/Milestones/Data/wandb/run-20211008_160507-3he1mes5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Training loss</td><td>0.04561</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>global_step</td><td>2661</td></tr><tr><td>_runtime</td><td>387</td></tr><tr><td>_timestamp</td><td>1633734694</td></tr><tr><td>_step</td><td>56</td></tr><tr><td>eval_loss</td><td>0.08715</td></tr><tr><td>train_loss</td><td>0.00612</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Training loss</td><td>â–ˆâ–„â–…â–„â–…â–ƒâ–„â–„â–ƒâ–…â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>lr</td><td>â–ƒâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>global_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_runtime</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_timestamp</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval_loss</td><td>â–ˆâ–â–â–</td></tr><tr><td>train_loss</td><td>â–â–‚â–ˆâ–</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">efficient-sunset-36</strong>: <a href=\"https://wandb.ai/vionwinnie/T5%20-%20single%20task/runs/3he1mes5\" target=\"_blank\">https://wandb.ai/vionwinnie/T5%20-%20single%20task/runs/3he1mes5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5Model(\"t5\", \"t5-small\", args=model_args)\n",
    "model.train_model(combined_train_df, eval_data=combined_val_df)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv('singletask_noupsampling_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"max_seq_length\": 400,\n",
    "    \"eval_batch_size\": 4,\n",
    "    \"use_multiprocessing\": False,\n",
    "    \"num_beams\": 5,\n",
    "    \"do_sample\": True,\n",
    "    \"max_length\": 10,\n",
    "    \"top_k\": 10,\n",
    "    \"top_p\": 0.95,\n",
    "    \"num_return_sequences\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = T5Model(\"t5\",\"multitask\", args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf783f3e74b4486d87e7153a7213e5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e472af2182a14953a99aba6c59500cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the data for testing\n",
    "to_predict = [\n",
    "    prefix + \": \" + str(input_text)\n",
    "    for prefix, input_text in zip(eval_df[\"prefix\"].tolist(), eval_df[\"input_text\"].tolist())\n",
    "]\n",
    "truth = eval_df[\"target_text\"].tolist()\n",
    "tasks = eval_df[\"prefix\"].tolist()\n",
    "\n",
    "# Get the model predictions\n",
    "preds = model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for cur_pred in preds:\n",
    "    cur_pred = cur_pred[0].strip()\n",
    "    predicted_labels.append(cur_pred)\n",
    "\n",
    "val_labels = eval_df['target_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Question       0.88      0.97      0.92        36\n",
      "         Review       1.00      0.25      0.40         4\n",
      "Stylus problems       1.00      1.00      1.00         2\n",
      "      Templates       0.71      0.62      0.67         8\n",
      "\n",
      "       accuracy                           0.86        50\n",
      "      macro avg       0.90      0.71      0.75        50\n",
      "   weighted avg       0.86      0.86      0.84        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Monitoring Using Wandb\n",
    "\n",
    "<img src=\"../Images (if applicable)/M3_wandb.png\" alt = \"test pic\" style = \"width:1182px; height=702px;\">\n",
    "\n",
    "Both train and val loss are decreasing steadily over the course of training. We don't see any overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Our model weighted F1-score improved from 0.81 to 0.84 after learning the representations from other subreddits. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
