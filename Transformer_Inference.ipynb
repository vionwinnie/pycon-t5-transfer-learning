{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Model to Datahub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Upload model to transformer datahub\n",
    "- create an account\n",
    "- create a model repo \n",
    "- need to delete `tokenizer_config.json` before git commit to be used by T5Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 't5-reddit' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt-get install git-lfs \n",
    "git lfs install\n",
    "git clone https://{user_name}:{password}@huggingface.co/{user_name}/{model_repo}\n",
    "git config --global user.email ${email}\n",
    "git config --global user.name ${name} \n",
    "\n",
    "# copy files over from model directory `cp ./multitask/* ./t5-reddit/`\n",
    "git status\n",
    "git add .\n",
    "git commit -m \"first push\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference [Prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Call the uploaded data using HuggingFace syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.t5 import T5Config, T5ForConditionalGeneration, T5Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"vionwinnie/t5-reddit\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"vionwinnie/t5-reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Score using `model.generate()` and append the predictied tag to `unlabelled_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"tag classification: This app is so amazing and I would like to tell you the best features I found of using this App, which is clicking through function. Thank you Goodnotes!\"\n",
    "test2 = \"title prediction: Can someone share the method you use to extract pages from a pdf and insert it into good notes notebook? I have been taking screen shots of the pages and inserting it as image but it’s inconvenient and not content is not very clear. I appreciate any tips. Thanks\"\n",
    "all_strings = [test1, test2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = tokenizer(all_strings,\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt',\n",
    "                        max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0th data\n",
      "['Review', 'How to extract pages from a pdf']\n"
     ]
    }
   ],
   "source": [
    "input_ids = input_batch[\"input_ids\"]\n",
    "attention_mask = input_batch[\"attention_mask\"]\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "batch_size = 4\n",
    "for i in range(0, len(all_strings), batch_size):\n",
    "    print(\"processing {}th data\".format(i))\n",
    "    subset_input_ids = input_ids[i:i+4]\n",
    "    subset_attention_masks = attention_mask[i:i+4]\n",
    "    if subset_input_ids.size()[0] >0:\n",
    "        prediction = model.generate(input_ids=subset_input_ids,\n",
    "                        attention_mask=subset_attention_masks,\n",
    "                        num_beams=4,\n",
    "                        max_length=300,\n",
    "                        do_sample=True,\n",
    "                        top_k=50,\n",
    "                        top_p=0.95,\n",
    "                        num_return_sequences=1)\n",
    "        for pred in prediction:\n",
    "            theme=tokenizer.decode(pred).replace('<pad>','').replace('</s>','').strip()\n",
    "            all_preds.append(theme)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag classification: This app is so amazing and I would like to tell you the best features I found of using this App, which is clicking through function. Thank you Goodnotes!\n",
      "prediction:   Review\n",
      "----------------------------------------------------------------------------------------------------\n",
      "title prediction: Can someone share the method you use to extract pages from a pdf and insert it into good notes notebook? I have been taking screen shots of the pages and inserting it as image but it’s inconvenient and not content is not very clear. I appreciate any tips. Thanks\n",
      "prediction:   How to extract pages from a pdf\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for task,pred in zip(all_strings, all_preds):\n",
    "    print(task)\n",
    "    print(\"prediction:   {}\".format(pred))\n",
    "    print(\"--\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
